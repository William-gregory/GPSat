{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9715a8dd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "#  DataLoader Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aeb37ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:31:54.977620Z",
     "iopub.status.busy": "2024-03-22T11:31:54.977447Z",
     "iopub.status.idle": "2024-03-22T11:31:57.583850Z",
     "shell.execute_reply": "2024-03-22T11:31:57.583339Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from GPSat.dataloader import DataLoader\n",
    "from GPSat import get_data_path\n",
    "from GPSat.utils import cprint\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b4ad37",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## load method\n",
    "\n",
    "read from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588c5a7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:31:57.586446Z",
     "iopub.status.busy": "2024-03-22T11:31:57.586130Z",
     "iopub.status.idle": "2024-03-22T11:31:58.330003Z",
     "shell.execute_reply": "2024-03-22T11:31:58.329487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--------------------\u001b[0m\n",
      "\u001b[1mloading individual csv files\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data_select': 0.225 seconds\n",
      "'load': 0.226 seconds\n",
      "         lon        lat                    datetime       z\n",
      "0 -57.190860  65.647048  2020-03-01 00:03:32.948838  0.0330\n",
      "1 -57.224372  65.679991  2020-03-01 00:03:36.667280  0.1057\n",
      "'data_select': 0.195 seconds\n",
      "'load': 0.195 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data_select': 0.315 seconds\n",
      "'load': 0.316 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cprint(\"-\"*20, \"BOLD\")\n",
    "cprint(\"loading individual csv files\", \"BOLD\")\n",
    "\n",
    "# load data, engine to use is determined by file name\n",
    "a = DataLoader.load(source=get_data_path(\"example\", \"A_RAW.csv\"))\n",
    "print(a.head(2))\n",
    "\n",
    "# specify engine, in this case a panda's read_* method\n",
    "b = DataLoader.load(source=get_data_path(\"example\", \"B_RAW.csv\"),\n",
    "                    engine=\"read_csv\")\n",
    "\n",
    "# provide additional arguments to read_csv\n",
    "c = DataLoader.load(source=get_data_path(\"example\", \"C_RAW.csv\"),\n",
    "                    engine=\"read_csv\",\n",
    "                    source_kwargs={\"sep\": ','})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6efa82e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## load method con't\n",
    "\n",
    "save tab seperated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ffc6b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:31:58.332186Z",
     "iopub.status.busy": "2024-03-22T11:31:58.331972Z",
     "iopub.status.idle": "2024-03-22T11:32:01.717246Z",
     "shell.execute_reply": "2024-03-22T11:32:01.716701Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--------------------\u001b[0m\n",
      "\u001b[1mloading from tab separated file\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data_select': 0.310 seconds\n",
      "'load': 0.310 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cprint(\"-\"*20, \"BOLD\")\n",
    "cprint(\"loading from tab separated file\", \"BOLD\")\n",
    "\n",
    "# (store and) read from tab seperated\n",
    "tsv_file = get_data_path(\"example\", \"tmp.tsv\")\n",
    "c.to_csv(tsv_file, sep=\"\\t\", index=False)\n",
    "\n",
    "# load tsv file, providing additional (source keyword) arguments\n",
    "# - which will be passed into pd.read_csv\n",
    "_ = DataLoader.load(source=tsv_file,\n",
    "                    engine=\"read_csv\",\n",
    "                    source_kwargs={\"sep\": \"\\t\", \"keep_default_na\": True})\n",
    "\n",
    "pd.testing.assert_frame_equal(c, _)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895bce37",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## read in multiple files in a folder\n",
    "\n",
    "identify files using a regular expression\n",
    "apply col_funcs after loaded into memory - see below for details on col_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d90e77a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:01.719934Z",
     "iopub.status.busy": "2024-03-22T11:32:01.719698Z",
     "iopub.status.idle": "2024-03-22T11:32:02.750500Z",
     "shell.execute_reply": "2024-03-22T11:32:02.749921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "reading files from:\n",
      "/home/runner/work/GPSat/GPSat/data/example/\n",
      "that match regular expression: _RAW\\.csv$\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'read_from_multiple_files': 1.017 seconds\n",
      "\u001b[1mhead:\u001b[0m\n",
      "         lon        lat                   datetime       z source\n",
      "0  59.944790  82.061122 2020-03-01 13:48:50.295540  0.0599      C\n",
      "1  59.939555  82.063771 2020-03-01 13:48:50.354648  0.0139      C\n",
      "\u001b[1mdtypes:\u001b[0m\n",
      "lon                float64\n",
      "lat                float64\n",
      "datetime    datetime64[ns]\n",
      "z                  float64\n",
      "source              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_funcs = {\n",
    "    \"source\": {\n",
    "        \"func\": lambda x: re.sub('_RAW.*$', '', os.path.basename(x)),\n",
    "        \"filename_as_arg\": True\n",
    "    },\n",
    "    \"datetime\": {\n",
    "        \"func\": lambda x: x.astype('datetime64[ns]'),\n",
    "        \"col_args\": \"datetime\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# can also supply a list of sub-directories (sub_dirs) to look instead of file_dirs\n",
    "_ = DataLoader.read_flat_files(file_dirs=get_data_path(\"example\"),\n",
    "                               file_regex=\"_RAW\\.csv$\",\n",
    "                               col_funcs=col_funcs)\n",
    "\n",
    "cprint(\"head:\", \"BOLD\")\n",
    "print(_.head(2))\n",
    "\n",
    "cprint(\"dtypes:\", \"BOLD\")\n",
    "print(_.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2533cef",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## save and read from parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "787651a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:02.752736Z",
     "iopub.status.busy": "2024-03-22T11:32:02.752337Z",
     "iopub.status.idle": "2024-03-22T11:32:06.947459Z",
     "shell.execute_reply": "2024-03-22T11:32:06.946935Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--------------------\u001b[0m\n",
      "\u001b[1mloading from parquet file\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data_select': 0.080 seconds\n",
      "'load': 0.080 seconds\n"
     ]
    }
   ],
   "source": [
    "cprint(\"-\"*20, \"BOLD\")\n",
    "cprint(\"loading from parquet file\", \"BOLD\")\n",
    "# store as h5 file - to demonstrate reading in\n",
    "parq_tmp = get_data_path(\"example\", \"tmp.parquet\")\n",
    "\n",
    "# NOTE: fastparquet allows for appending, alternative is pyarrow (or 'auto')\n",
    "_.to_parquet(parq_tmp, engine=\"fastparquet\")\n",
    "\n",
    "# read data from parquet file - using the pyarrow engine\n",
    "df = DataLoader.load(source=parq_tmp)\n",
    "\n",
    "pd.testing.assert_frame_equal(df, _)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620e14ef",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## save and read from hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d19ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:06.950014Z",
     "iopub.status.busy": "2024-03-22T11:32:06.949710Z",
     "iopub.status.idle": "2024-03-22T11:32:14.515042Z",
     "shell.execute_reply": "2024-03-22T11:32:14.514477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--------------------\u001b[0m\n",
      "\u001b[1mloading from hdf5 file\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.400 seconds\n",
      "'load': 0.401 seconds\n"
     ]
    }
   ],
   "source": [
    "cprint(\"-\"*20, \"BOLD\")\n",
    "cprint(\"loading from hdf5 file\", \"BOLD\")\n",
    "# store as h5 file - to demonstrate reading in\n",
    "hdf5_tmp = get_data_path(\"example\", \"tmp.h5\")\n",
    "hdf5_table = \"data\"\n",
    "with pd.HDFStore(hdf5_tmp, mode=\"w\") as store:\n",
    "    # setting data_columns = True so will be searchable\n",
    "    store.append(key=hdf5_table, value=_, data_columns=True)\n",
    "\n",
    "# read data from table in hdf5\n",
    "df = DataLoader.load(source=hdf5_tmp,\n",
    "                     table=hdf5_table)\n",
    "\n",
    "pd.testing.assert_frame_equal(df, _)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f4544a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## save and read from netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e4adb19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:14.517370Z",
     "iopub.status.busy": "2024-03-22T11:32:14.517183Z",
     "iopub.status.idle": "2024-03-22T11:32:27.115340Z",
     "shell.execute_reply": "2024-03-22T11:32:27.114783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--------------------\u001b[0m\n",
      "\u001b[1mloading from netcdf file\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data_select': 0.184 seconds\n",
      "'load': 0.220 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cprint(\"-\"*20, \"BOLD\")\n",
    "cprint(\"loading from netcdf file\", \"BOLD\")\n",
    "\n",
    "# first - save to file, using multi index for dimensions\n",
    "tmp_ = _.set_index(['datetime', 'source'])\n",
    "ds = xr.Dataset.from_dataframe(tmp_)\n",
    "\n",
    "netcdf_tmp = get_data_path(\"example\", \"tmp.nc\")\n",
    "ds.to_netcdf(path=netcdf_tmp)\n",
    "\n",
    "# read data from netcdf file\n",
    "# NOTE: this will comeback with a multi index - can reset with reset_index=True\n",
    "nc = DataLoader.load(source=netcdf_tmp)\n",
    "\n",
    "# netcdf will have nans for missing values\n",
    "# - netcdf effectively stores values in n-d array with the\n",
    "# - dimensions determined by an index when converting from DataFrame\n",
    "# nc.dropna(inplace=True)\n",
    "\n",
    "# sort indices (and data) in the same way\n",
    "tmp_.sort_index(inplace=True)\n",
    "nc.sort_index(inplace=True)\n",
    "\n",
    "# ensure columns are in same order - might not be needed\n",
    "nc = nc[tmp_.columns]\n",
    "\n",
    "pd.testing.assert_frame_equal(tmp_, nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60700f20",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## use 'where' to select subset without having to read entirely into memory\n",
    "\n",
    "this is accomplished by using a 'where dict', containing the following keys\n",
    "- 'col' : the column of the data used for selection\n",
    "- 'comp': the comparison to used, e.g. \">\", \">=\", \"==\", \"!=\", \"<=\", \"<\"\n",
    "- 'val' : value being compared to column values\n",
    "\n",
    "where using hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1feaeefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:27.117672Z",
     "iopub.status.busy": "2024-03-22T11:32:27.117495Z",
     "iopub.status.idle": "2024-03-22T11:32:30.633648Z",
     "shell.execute_reply": "2024-03-22T11:32:30.633097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--------------------\u001b[0m\n",
      "\u001b[1mapplying 'where' dictionaries - selecting data at source\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.281 seconds\n",
      "'load': 0.282 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.501 seconds\n",
      "'load': 0.501 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.345 seconds\n",
      "'load': 0.346 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = _.loc[_['source'] == \"A\"].copy(True)\n",
    "\n",
    "cprint(\"-\"*20, \"BOLD\")\n",
    "cprint(\"applying 'where' dictionaries - selecting data at source\", \"BOLD\")\n",
    "\n",
    "df = DataLoader.load(source=hdf5_tmp,\n",
    "                     table=hdf5_table,\n",
    "                     where={\"col\": \"source\", \"comp\": \"==\", \"val\": \"A\"})\n",
    "\n",
    "pd.testing.assert_frame_equal(a, df)\n",
    "\n",
    "# hdf5 allows for a list of values to be provided\n",
    "df = DataLoader.load(source=hdf5_tmp,\n",
    "                     table=hdf5_table,\n",
    "                     where={\"col\": \"source\", \"comp\": \"==\", \"val\": [\"A\", \"B\"]}\n",
    "                     )\n",
    "\n",
    "# unique doesn't sort?\n",
    "np.testing.assert_array_equal(np.sort(df['source'].unique()),\n",
    "                              np.array(['A', 'B'], dtype=object))\n",
    "\n",
    "\n",
    "# multiple 'where dicts' can be combined in a list\n",
    "# - they will be combined with an AND operation\n",
    "df = DataLoader.load(source=hdf5_tmp,\n",
    "                     table=hdf5_table,\n",
    "                     where=[\n",
    "                        {\"col\": \"source\", \"comp\": \"==\", \"val\": \"A\"},\n",
    "                        {\"col\": \"lat\", \"comp\": \">=\", \"val\": 65.0}\n",
    "                     ]\n",
    "                     )\n",
    "\n",
    "assert df['lat'].min() >= 65.0\n",
    "\n",
    "pd.testing.assert_frame_equal(a.loc[a['lat'] >= 65.0], df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a206ccd0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "where using netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b813b89a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:30.636130Z",
     "iopub.status.busy": "2024-03-22T11:32:30.635927Z",
     "iopub.status.idle": "2024-03-22T11:32:30.896075Z",
     "shell.execute_reply": "2024-03-22T11:32:30.895511Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data_select': 0.152 seconds\n",
      "'load': 0.170 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# apply where_dict to netcdf file - must be for the index, in thise case \"source\" or \"datetime\"\n",
    "nc = DataLoader.load(source=netcdf_tmp,\n",
    "                     where=[\n",
    "                         {\"col\": \"source\", \"comp\": \"==\", \"val\": \"A\"}\n",
    "                     ],\n",
    "                     reset_index=True\n",
    "                     )\n",
    "\n",
    "np.testing.assert_array_equal(nc['source'].unique(), np.array(['A'], dtype=object))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd774a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "where using parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6329e0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:30.898179Z",
     "iopub.status.busy": "2024-03-22T11:32:30.897951Z",
     "iopub.status.idle": "2024-03-22T11:32:33.651639Z",
     "shell.execute_reply": "2024-03-22T11:32:33.651003Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data_select': 0.055 seconds\n",
      "'load': 0.055 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data_select': 0.049 seconds\n",
      "'load': 0.050 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# using parquet / read_parquet the where's get convert to 'filters', see pd.read_parquet for more details\n",
    "\n",
    "df = DataLoader.load(source=parq_tmp,\n",
    "                     where=[\n",
    "                        {\"col\": \"source\", \"comp\": \"==\", \"val\": \"A\"},\n",
    "                        {\"col\": \"lat\", \"comp\": \">=\", \"val\": 65.0}\n",
    "                     ]\n",
    "                     )\n",
    "assert df['lat'].min() >= 65.0\n",
    "\n",
    "pd.testing.assert_frame_equal(a.loc[a['lat'] >= 65.0], df)\n",
    "\n",
    "\n",
    "# NOTE: using querying on datetime / timestamp objects need to convert to datetime via -\n",
    "# pd.Timestamp\n",
    "\n",
    "max_time = pd.Timestamp(\"2020-03-05\")\n",
    "df = DataLoader.load(source=parq_tmp,\n",
    "                     where=[\n",
    "                        {\"col\": \"datetime\", \"comp\": \"<=\", \"val\": max_time}\n",
    "                     ]\n",
    "                     )\n",
    "\n",
    "pd.testing.assert_frame_equal(_.loc[_['datetime'] <= max_time], df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd60bd9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## use 'row_select' to select subset after data is loaded into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "894230a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:33.654284Z",
     "iopub.status.busy": "2024-03-22T11:32:33.653937Z",
     "iopub.status.idle": "2024-03-22T11:32:40.309956Z",
     "shell.execute_reply": "2024-03-22T11:32:40.309302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--------------------\u001b[0m\n",
      "\u001b[1mrow_select examples\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.395 seconds\n",
      "'load': 0.456 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.279 seconds\n",
      "'load': 0.280 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.404 seconds\n",
      "'load': 0.431 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.393 seconds\n",
      "'load': 0.420 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cprint(\"-\"*20, \"BOLD\")\n",
    "cprint(\"row_select examples\", \"BOLD\")\n",
    "\n",
    "\n",
    "\n",
    "# 'where dict' can be used for row_select\n",
    "df0 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      row_select={\"col\": \"source\", \"comp\": \"==\", \"val\": \"A\"})\n",
    "\n",
    "# NOTE: using where is faster\n",
    "df1 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      where={\"col\": \"source\", \"comp\": \"==\", \"val\": \"A\"})\n",
    "\n",
    "pd.testing.assert_frame_equal(df0, df1)\n",
    "\n",
    "# row select allows for using lambda functions that returns a bool array\n",
    "# - col_args specify the columns of the data to pass in as arguments to \"func\"\n",
    "df0 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      row_select={\n",
    "                          \"func\": lambda x: x >= 65.0,\n",
    "                          \"col_args\": \"lat\"\n",
    "                      })\n",
    "\n",
    "assert df0['lat'].min() >= 65.0\n",
    "\n",
    "# the lambda functions can be supplied as strings - useful when passing parameters from a json configuration\n",
    "# NOTE: if func is a string it will be converted with eval(...)\n",
    "df1 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      row_select={\n",
    "                          \"func\": \"lambda x: x >= 65.0\",\n",
    "                          \"col_args\": \"lat\"\n",
    "                      })\n",
    "\n",
    "pd.testing.assert_frame_equal(df0, df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8a2d1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Advanced: more row_select and where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b90c935d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:40.312701Z",
     "iopub.status.busy": "2024-03-22T11:32:40.312500Z",
     "iopub.status.idle": "2024-03-22T11:32:42.753006Z",
     "shell.execute_reply": "2024-03-22T11:32:42.752451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--------------------\u001b[0m\n",
      "\u001b[1mmore row_select and where\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.392 seconds\n",
      "'load': 0.420 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.397 seconds\n",
      "'load': 0.415 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.394 seconds\n",
      "'load': 0.406 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.393 seconds\n",
      "'load': 0.417 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.389 seconds\n",
      "'load': 0.455 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.281 seconds\n",
      "'load': 0.300 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cprint(\"-\"*20, \"BOLD\")\n",
    "cprint(\"more row_select and where\", \"BOLD\")\n",
    "\n",
    "\n",
    "# multiple columns can be supplied\n",
    "df2 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      row_select={\n",
    "                          \"func\": \"lambda x, y: (x >= 65.0) & (y == 'A')\",\n",
    "                          \"col_args\": [\"lat\", \"source\"]\n",
    "                      })\n",
    "\n",
    "assert df2['lat'].min() >= 65.0\n",
    "np.testing.assert_array_equal(df2['source'].unique(), np.array(['A'], dtype=object))\n",
    "\n",
    "\n",
    "# column values can be supplied via col_kwargs\n",
    "# - this can be useful if a more involved function is supplied\n",
    "df2 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      row_select={\n",
    "                          \"func\": \"lambda x, y: (x >= 65.0) & (y >= 0)\",\n",
    "                          \"col_kwargs\": {\n",
    "                              \"x\": \"lat\", \"y\": \"lon\"\n",
    "                          }\n",
    "                      })\n",
    "\n",
    "assert df2['lat'].min() >= 65.0\n",
    "assert df2['lon'].min() >= 0.0\n",
    "\n",
    "# row_select can be negated (or inverted) - flipping Trues to False and vice versa\n",
    "# - this can be useful when defining hold out data\n",
    "# - e.g. create a row_select that selects the desired data and then use negate to make sure it's excluded\n",
    "df3 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      row_select={\n",
    "                          \"func\": \"lambda x: (x >= 65.0)\",\n",
    "                          \"col_args\": \"lat\",\n",
    "                          \"negate\": True\n",
    "                      })\n",
    "\n",
    "assert df3['lat'].max() < 65.0\n",
    "\n",
    "\n",
    "df3 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      row_select={\n",
    "                          \"func\": \"lambda x, y: (x >= 65.0) & (y >= 0)\",\n",
    "                          \"col_kwargs\": {\n",
    "                              \"x\": \"lat\", \"y\": \"lon\"\n",
    "                          },\n",
    "                          \"negate\": True\n",
    "                      })\n",
    "\n",
    "# there should be no rows with lat>=65.0  AND lon>=0\n",
    "assert len(df3.loc[(df3['lat'] >= 65.0) & (df3['lon'] >= 0.0)]) == 0\n",
    "\n",
    "# multiple row_selects can be combined via a list\n",
    "# - similar to where, they are combined via an AND boolean operation\n",
    "\n",
    "\n",
    "df4 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      row_select=[\n",
    "                          {\"col\": \"source\", \"comp\": \"==\", \"val\": \"A\"},\n",
    "                          {\n",
    "                              \"func\": \"lambda x: (x >= 65.0)\",\n",
    "                              \"col_args\": \"lat\"\n",
    "                          },\n",
    "                          {\n",
    "                              \"func\": \"lambda y: y >= 0.0\",\n",
    "                              \"col_kwargs\": {\"y\": \"lon\"}\n",
    "\n",
    "                          },\n",
    "                          {\n",
    "                              \"func\": \"lambda y: y >= 0.0\",\n",
    "                              \"col_args\": \"z\"\n",
    "\n",
    "                          }\n",
    "                      ])\n",
    "\n",
    "assert df4['lat'].min() >= 65.0\n",
    "assert df4['lon'].min() >= 0.0\n",
    "assert df4['z'].min() >= 0.0\n",
    "np.testing.assert_array_equal(df4['source'].unique(), np.array(['A'], dtype=object))\n",
    "\n",
    "\n",
    "# where and row_selects can be used together\n",
    "# - where's are used first, when reading data in from file\n",
    "# - row_selects are applied to the data in memory\n",
    "df5 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      where={\"col\": \"source\", \"comp\": \"==\", \"val\": \"A\"},\n",
    "                      row_select={\"col\": \"source\", \"comp\": \"==\", \"val\": \"B\"})\n",
    "assert len(df5) == 0\n",
    "\n",
    "# TODO: show where and row_select using netcdf data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d02d3",
   "metadata": {},
   "source": [
    "## Advanced: col_funcs - apply functions to create or modify columns\n",
    "\n",
    "columns functions take in a dict, with the key being the new (or existing) column and the value\n",
    "- a dict specifying how the column shall be created\n",
    "- NOTE: by default columns are extracted from dataframe columns as numpy arrays (so no need to take values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "430a654a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:42.755303Z",
     "iopub.status.busy": "2024-03-22T11:32:42.754979Z",
     "iopub.status.idle": "2024-03-22T11:32:47.966432Z",
     "shell.execute_reply": "2024-03-22T11:32:47.965710Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--------------------\u001b[0m\n",
      "\u001b[1mapplying col(umn)_func(tion)s to data after reading into memory\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.397 seconds\n",
      "'load': 0.403 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.403 seconds\n",
      "'load': 0.453 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n",
      "'data_select': 0.396 seconds\n",
      "'load': 0.397 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cprint(\"-\"*20, \"BOLD\")\n",
    "cprint(\"applying col(umn)_func(tion)s to data after reading into memory\", \"BOLD\")\n",
    "\n",
    "\n",
    "# add a column\n",
    "df1 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      col_funcs={\n",
    "                          \"z_pos\": {\n",
    "                              \"func\": \"lambda x: np.where(x>0, x, np.nan)\",\n",
    "                              \"col_args\": \"z\"\n",
    "                          }\n",
    "                      })\n",
    "assert np.all(df1.loc[np.isnan(df1['z_pos']), \"z\"] <= 0)\n",
    "\n",
    "\n",
    "# modify / create a 'date' column\n",
    "df1 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table,\n",
    "                      col_funcs={\n",
    "                          \"date\": {\n",
    "                              \"func\": \"lambda x: x.astype('datetime64[D]')\",\n",
    "                              \"col_args\": \"datetime\"\n",
    "                          }\n",
    "                      })\n",
    "\n",
    "# reference dataframe: column modified after load\n",
    "df0 = DataLoader.load(source=hdf5_tmp,\n",
    "                      table=hdf5_table)\n",
    "\n",
    "# convert datetime from\n",
    "df0['date'] = df0['datetime'].values.astype('datetime64[D]')\n",
    "\n",
    "pd.testing.assert_frame_equal(df0, df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8564c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "add_data_to_col, col_select, reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb98f0b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:47.969551Z",
     "iopub.status.busy": "2024-03-22T11:32:47.969109Z",
     "iopub.status.idle": "2024-03-22T11:32:47.971987Z",
     "shell.execute_reply": "2024-03-22T11:32:47.971497Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: add simple examples of above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf8f7e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "remove tmp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8082cd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T11:32:47.974014Z",
     "iopub.status.busy": "2024-03-22T11:32:47.973834Z",
     "iopub.status.idle": "2024-03-22T11:32:48.019572Z",
     "shell.execute_reply": "2024-03-22T11:32:48.019015Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--------------------\u001b[0m\n",
      "\u001b[1mcleaning up: delete tmp files\u001b[0m\n",
      "removing tmp file: /home/runner/work/GPSat/GPSat/data/example/tmp.nc\n",
      "removing tmp file: /home/runner/work/GPSat/GPSat/data/example/tmp.h5\n",
      "removing tmp file: /home/runner/work/GPSat/GPSat/data/example/tmp.parquet\n",
      "removing tmp file: /home/runner/work/GPSat/GPSat/data/example/tmp.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cprint(\"-\"*20, \"BOLD\")\n",
    "cprint(\"cleaning up: delete tmp files\", \"BOLD\")\n",
    "\n",
    "# delete tmp files\n",
    "for i in [netcdf_tmp, hdf5_tmp, parq_tmp, tsv_file]:\n",
    "    print(f\"removing tmp file: {i}\")\n",
    "    os.remove(i)\n",
    "    assert not os.path.exists(i)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
